{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7661aa",
   "metadata": {
    "id": "DyAhNSSJ1qC4"
   },
   "source": [
    "#bike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "45a06448",
   "metadata": {
    "executionInfo": {
     "elapsed": 2724,
     "status": "ok",
     "timestamp": 1633486367286,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "ZDsDiL689VNY"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from pandas import Series\n",
    "import math\n",
    "import numpy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "SMALL_SIZE = 20\n",
    "MEDIUM_SIZE = 23\n",
    "BIGGER_SIZE = 25\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE) # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE) # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE) # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE) # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE) # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE) # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE) # fontsize of the figure title\n",
    "\n",
    "data = pd.read_csv(os.path.realpath('./SeoulBikeData (1).csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee569a55",
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1633486367289,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "xQlGEgBq9VPh"
   },
   "outputs": [],
   "source": [
    "data['Holiday']=data['Holiday'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c425b58",
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1633486367289,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "7TlUv15E9VRt"
   },
   "outputs": [],
   "source": [
    "data['Seasons']=data['Seasons'].factorize()[0]\n",
    "data['Functioning Day']=data['Functioning Day'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "329956c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1633486367290,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "6FxkSurA9VUE",
    "outputId": "5722c7f5-ac0f-48ba-9058-10f4fccdb03c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        254\n",
       "1        204\n",
       "2        173\n",
       "3        107\n",
       "4         78\n",
       "        ... \n",
       "8755    1003\n",
       "8756     764\n",
       "8757     694\n",
       "8758     712\n",
       "8759     584\n",
       "Name: Rented Bike Count, Length: 8760, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rented Bike Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b51f276",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633486367290,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "eAnh40DV9VWa"
   },
   "outputs": [],
   "source": [
    "data=data.drop(['Hour'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e8fe2b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1633486367290,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "79eM7zrc9VYj",
    "outputId": "36746a89-b595-4db2-aa39-0479ae658584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rented Bike Count', 'Temperature', 'Humidity(%)', 'Wind speed (m/s)',\n",
       "       'Visibility (10m)', 'Dew point temperature', 'Solar Radiation (MJ/m2)',\n",
       "       'Rainfall(mm)', 'Snowfall (cm)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[1:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07b49973",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1633486367291,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "CaoBZRtZ9vn9",
    "outputId": "c2118ce1-84cf-487e-cb36-37e3e9abf1df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=data.columns[1:-3] \n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1b350b29",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1633486367291,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "wujZa93c9vp0"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "values = data[cols].values.reshape(-1,9)\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled=scaler.fit_transform(values)\n",
    "#scaled = (values-(np.min(values)))/(np.max(values)-(np.min(values)))\n",
    "#scaled = (values - np.mean(values))/np.std(values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e1fd2984",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1633486367291,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "dkY2XEaT-VU1",
    "outputId": "d84ec9fd-fd99-41ca-e38e-08facef7a823"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3556.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "be38b370",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1633486367667,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "GazyNd8DVLdv",
    "outputId": "7855d0f1-913e-43cf-b89a-ba544867b789"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-30.6"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd2065ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1633486367668,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "hVrUxIYnVLbh",
    "outputId": "9987276f-60bb-49b2-ce8a-0f5d3aa6653f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3586.6"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(values)-np.min(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "33b8192f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633486367668,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "dc3I72Uk5cpm",
    "outputId": "bc734dc4-7622-441a-9f43-0b192ec8b783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.preprocessing import MinMaxScaler\\nvalues = data[cols].values.reshape(-1,9)\\nvalues = values.astype('float32')\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values) \\n\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "values = data[cols].values.reshape(-1,9)\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175224df",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633486367669,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "yNDQXnpV-eWB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5292ecca",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633486367669,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "ZPMgKJGb9vr5"
   },
   "outputs": [],
   "source": [
    "# fill missing values with a value at the same time one day ago\n",
    "def fill_missing(values):\n",
    "    one_day = 7 * 24\n",
    "    for row in range(values.shape[0]):\n",
    "        for col in range(values.shape[1]):\n",
    "            if values[row,0]==0:\n",
    "                values[row,0] = values[row - one_day,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "778db1b3",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633486367669,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "iyuzMESv9vuS"
   },
   "outputs": [],
   "source": [
    "fill_missing(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f26e5012",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633486367670,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "fBsc1yeE9VbD",
    "outputId": "5f8b535f-025d-494b-e784-ba28874e3fae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.DataFrame(values)[0]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be09ad",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1633486367670,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "Yb3eWO4H97ws"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "86742efe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1633486367671,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "jL8mMzxM97y9",
    "outputId": "3a055c6a-d0d7-48c2-8d9b-1c6665f29c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7008 876 876\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = int(len(scaled) * 0.80)\n",
    "val_size = int(len(scaled) * 0.10)\n",
    "\n",
    "test_size = len(scaled) - train_size-val_size\n",
    "train,val, test = scaled[0:train_size,:],scaled[train_size:train_size+val_size,:], scaled[train_size+val_size:,:]\n",
    "print(len(train),len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e8f2e306",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633486367671,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "-M48YJg-971g"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset_multistep(dataset, look_back=1,predict=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back-predict):\n",
    "        a = dataset[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+ look_back-1: i+ look_back+predict-1, 0])\n",
    "    print(len(dataY))\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "03918b98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633486367671,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "Uf9I_XaP974K",
    "outputId": "f1599efd-b8cc-4f9c-fd6c-556297a2cd19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6816\n",
      "684\n",
      "684\n"
     ]
    }
   ],
   "source": [
    "look_back = 168\n",
    "predict=24\n",
    "\n",
    "trainX, trainY = create_dataset_multistep(train, look_back,predict)\n",
    "valX, valY = create_dataset_multistep(val, look_back,predict)\n",
    "testX, testY = create_dataset_multistep(test, look_back,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab2ced8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 168, 9)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "961803cd",
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1633486367921,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "u_1ry8uG-BB0"
   },
   "outputs": [],
   "source": [
    "def gradient_importance(seq, model):\n",
    "\n",
    "    seq = tf.Variable(seq[np.newaxis,:,:], dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(seq)\n",
    "\n",
    "    grads = tape.gradient(predictions, seq)\n",
    "    grads = tf.reduce_mean(grads, axis=1).numpy()[0]\n",
    "    \n",
    "    return grads\n",
    "\n",
    "def gradient_weight(seq, model):\n",
    "\n",
    "    seq = tf.Variable(seq[np.newaxis,:,:], dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(seq)\n",
    "\n",
    "    grad = tape.gradient(predictions, seq)\n",
    "    #gr=grads\n",
    "    #grads = tf.reduce_mean(grads, axis=1).numpy()[0]\n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def activation_grad(seq, model):\n",
    "    \n",
    "    seq = seq[np.newaxis,:,:]\n",
    "    grad_model = Model([model.inputs], \n",
    "                       [model.get_layer('extractor').output, \n",
    "                        model.output])\n",
    "\n",
    "    # Obtain the predicted value and the intermediate filters\n",
    "    with tf.GradientTape() as tape:\n",
    "        seq_outputs, predictions = grad_model(seq)\n",
    "\n",
    "    # Extract filters and gradients\n",
    "    output = seq_outputs[0]\n",
    "    grads = tape.gradient(predictions, seq_outputs)[0]\n",
    "\n",
    "    # Average gradients spatially\n",
    "    weights = tf.reduce_mean(grads, axis=0)\n",
    "    \n",
    "    # Get a ponderated map of filters according to grad importance\n",
    "    cam = np.ones(output.shape[0], dtype=np.float32)\n",
    "    for index, w in enumerate(weights):\n",
    "        cam += w * output[:, index]\n",
    "\n",
    "    time = int(seq.shape[1]/output.shape[0])\n",
    "    cam = zoom(cam.numpy(), time, order=1)\n",
    "    heatmap = (cam - cam.min())/(cam.max() - cam.min())\n",
    "    \n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e19baf",
   "metadata": {},
   "source": [
    "## integrated_gradient_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6522723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integrated_gradients_m(img_input, top_pred_idx, baseline2=None, num_steps=50):\n",
    "    seq_input = X_test[1]\n",
    "    \n",
    "    mean = np.nanmean(seq_input)\n",
    "    baseline2 = np.full(seq_input.shape, mean)\n",
    "    # 1. Do interpolation.\n",
    "    seq_input = seq_input.astype(np.float32)\n",
    "    interpolated_seq = [\n",
    "        baseline2 + (step / num_steps) * (seq_input - baseline2)\n",
    "        for step in range(num_steps + 1)\n",
    "    ]\n",
    "\n",
    "    # 3. Get the gradients\n",
    "    grads = []\n",
    "    for i, seq in enumerate(interpolated_seq):\n",
    "        seq = tf.expand_dims(seq, axis=0)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(seq)\n",
    "            preds = model(seq)\n",
    "        grad = tape.gradient(preds, seq)\n",
    "        grads.append(grad[0])\n",
    "    grads = tf.convert_to_tensor(grads, dtype=tf.float32)\n",
    "\n",
    "    # 4. Approximate the integral using the trapezoidal rule\n",
    "    grads = (grads[:-1] + grads[1:]) / 2.0\n",
    "    avg_grads = tf.reduce_mean(grads, axis=0)\n",
    "\n",
    "    # 5. Calculate integrated gradients and return\n",
    "    integrated_grads = (seq_input - baseline2) * avg_grads\n",
    "    return integrated_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5c7b3",
   "metadata": {},
   "source": [
    "## gradient_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73d7bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_importance(seq, model):\n",
    "\n",
    "    seq = tf.Variable(seq[np.newaxis,:,:], dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(seq)\n",
    "\n",
    "    grads = tape.gradient(predictions, seq)\n",
    "    grads = tf.reduce_mean(grads, axis=1).numpy()[0]\n",
    "    \n",
    "    return grads\n",
    "\n",
    "\n",
    "\n",
    "def activation_grad(seq, model):\n",
    "    \n",
    "    seq = seq[np.newaxis,:,:]\n",
    "    grad_model = Model([model.inputs], \n",
    "                       [model.get_layer('extractor').output, \n",
    "                        model.output])\n",
    "\n",
    "    # Obtain the predicted value and the intermediate filters\n",
    "    with tf.GradientTape() as tape:\n",
    "        seq_outputs, predictions = grad_model(seq)\n",
    "\n",
    "    # Extract filters and gradients\n",
    "    output = seq_outputs[0]\n",
    "    grads = tape.gradient(predictions, seq_outputs)[0]\n",
    "\n",
    "    # Average gradients spatially\n",
    "    weights = tf.reduce_mean(grads, axis=0)\n",
    "    \n",
    "    # Get a ponderated map of filters according to grad importance\n",
    "    cam = np.ones(output.shape[0], dtype=np.float32)\n",
    "    for index, w in enumerate(weights):\n",
    "        cam += w * output[:, index]\n",
    "\n",
    "    time = int(seq.shape[1]/output.shape[0])\n",
    "    cam = zoom(cam.numpy(), time, order=1)\n",
    "    heatmap = (cam - cam.min())/(cam.max() - cam.min())\n",
    "    \n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c7f5c0a",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1633486367922,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "nBv0iPcp-BEJ"
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ce3fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b0c46b",
   "metadata": {
    "id": "ELjbTRKu1qFK"
   },
   "source": [
    "mtex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "14797ee3",
   "metadata": {
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1633486368820,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "x7-VO8oF2Tfo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 168, 9, 1)\n",
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 168, 9, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 168, 9, 16)        912       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 168, 9, 32)        16928     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 168, 9, 1)         33        \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 168, 9)            0         \n",
      "_________________________________________________________________\n",
      "extractor (Conv1D)           (None, 168, 64)           1792      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10752)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                344096    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 24)                792       \n",
      "=================================================================\n",
      "Total params: 364,553\n",
      "Trainable params: 364,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "first_input = Input(shape=(168,9,1))\n",
    "\n",
    "in0=Conv2D(filters=16, kernel_size=(168//3,1),input_shape=(168,9,1), activation='relu',padding='same')(first_input)\n",
    "#in1= BatchNormalization(scale=False)(in1)\n",
    "\n",
    "in1=Conv2D(filters=32, kernel_size=(168//5,1), activation='relu',padding='same')(in0)\n",
    "#in0= BatchNormalization(scale=False)(in0)\n",
    "#in1=Conv1D(filters=64, kernel_size=3, activation='relu',padding='same')(in0)\n",
    "\n",
    "in1=Conv2D(filters=1, kernel_size=1, activation='relu',padding='same')(in1)\n",
    "#in1= BatchNormalization(scale=False)(in1)\n",
    "print(in1.shape)\n",
    "in1 = Reshape((168,9))(in1)\n",
    "in0=Conv1D(filters=64, kernel_size=3, activation='relu',padding='same',name='extractor')(in1)\n",
    "#in1= BatchNormalization(scale=False)(in1)\n",
    "\n",
    "#in1=Conv1D(filters=64, kernel_size=2, activation='relu',padding='same')(in0)\n",
    "#in0= BatchNormalization(scale=False)(in0)\n",
    "#in1=Conv1D(filters=64, kernel_size=3, activation='relu',padding='same')(in0)\n",
    "\n",
    "#in1=Conv1D(filters=64, kernel_size=1, activation='relu',padding='same',name='extractor')(in1)\n",
    "#in1=add([in0,in1],name='extractor')\n",
    "#attn_layer = AttentionLayer(name='attention_layer')\n",
    "#attn_out, attn_states = attn_layer([in1,in1])\n",
    "\n",
    "    # Concat attention input and LSTM output, in original code it was decoder LSTM\n",
    "#concat_out = Concatenate(axis=-1, name='concat_layer')([in1, attn_out])\n",
    "#in1=MaxPooling1D(pool_size=2,name='extractor')(in1)\n",
    "\n",
    "#in1=add([in0,in1])\n",
    "in1=Flatten()(in0)\n",
    "#in1=Dense(50, activation='relu')(in1)\n",
    "#in1=LSTM(64)(in1)\n",
    "in1 = Dense(32,activation='relu')(in1)\n",
    "\n",
    "out=Dense(24)(in1)\n",
    "model=tf.keras.Model(inputs=[first_input],outputs=[out])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "checkpoint_path = \"saved_weights/bike_MTEX_multistep(4).hdf5\"\n",
    "cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_best_only=True,\n",
    "                                        monitor='val_loss',mode='min',\n",
    "                                                 verbose=1)\n",
    "model.summary()\n",
    "# fit model9\n",
    "# history=model.fit(trainX, trainY, epochs=200, batch_size=100, validation_data=(valX, valY), verbose=1, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ca22331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 00001: val_loss improved from inf to 0.03237, saving model to saved_weights\\bike_MTEX_multistep(4).hdf5\n",
      "69/69 [==============================] - 31s 452ms/step - loss: 0.0266 - val_loss: 0.0324\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 00002: val_loss improved from 0.03237 to 0.02809, saving model to saved_weights\\bike_MTEX_multistep(4).hdf5\n",
      "69/69 [==============================] - 32s 467ms/step - loss: 0.0131 - val_loss: 0.0281\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00003: val_loss improved from 0.02809 to 0.02683, saving model to saved_weights\\bike_MTEX_multistep(4).hdf5\n",
      "69/69 [==============================] - 30s 433ms/step - loss: 0.0098 - val_loss: 0.0268\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 00004: val_loss improved from 0.02683 to 0.02662, saving model to saved_weights\\bike_MTEX_multistep(4).hdf5\n",
      "69/69 [==============================] - 29s 423ms/step - loss: 0.0078 - val_loss: 0.0266\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00005: val_loss improved from 0.02662 to 0.02629, saving model to saved_weights\\bike_MTEX_multistep(4).hdf5\n",
      "69/69 [==============================] - 29s 425ms/step - loss: 0.0065 - val_loss: 0.0263\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 00006: val_loss did not improve from 0.02629\n",
      "69/69 [==============================] - 29s 423ms/step - loss: 0.0056 - val_loss: 0.0271\n",
      "Epoch 7/200\n",
      " 9/69 [==>...........................] - ETA: 22s - loss: 0.0053"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13892/66246532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(trainX, trainY, epochs=200, batch_size=100, validation_data=(valX, valY), verbose=1, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "80d4ca36",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633486368821,
     "user": {
      "displayName": "정찬휘",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00470938762273561607"
     },
     "user_tz": -540
    },
    "id": "7ah-SGxx2Thw"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"saved_weights/bike_MTEX_multistep(4).hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a97f9019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_2:0' shape=(None, 168, 9, 1) dtype=float32>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de5b1d",
   "metadata": {},
   "source": [
    "## integrated_gradient_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c57cc234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 168, 9)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4e5b09cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 9)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[id_].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dfbe1f77",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 420 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13892/2591872993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgrad_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_integrated_gradients_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mgrad_weight_abs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 420 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "id_=(24)*24+12\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "grad_weight = get_integrated_gradients_m(testX[id_], model, baseline2 = X_test[id_-24*7])\n",
    "\n",
    "grad_weight_abs = abs(grad_weight)\n",
    "\n",
    "grad_weight_abs_z = (grad_weight_abs-(np.min(grad_weight_abs)))/(np.max(grad_weight_abs)-(np.min(grad_weight_abs)))\n",
    "#grad_weight=grad_weight.reshape(48,4)\n",
    "\n",
    "print(grad_weight_abs_z.shape)\n",
    "plt.figure(figsize=(6,20))\n",
    "\n",
    "#plt.plot(X_test[8], 'k')\n",
    "a=grad_weight_abs_z.numpy()\n",
    "a=a.reshape(168,9)\n",
    "a=a.transpose()\n",
    "\n",
    "#print(a)\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,5))\n",
    "\n",
    "extent = [0 , 168, 0 , 9]\n",
    "y_label_list = [1,3,5,7,9]\n",
    "x_label_list = [0,24,48,72,96,120,144,168]\n",
    "ax.set_xticks([0,24,48,72,96,120,144,168])\n",
    "\n",
    "ax.set_yticks([10,30,50,70,90])\n",
    "\n",
    "ax.set_xticklabels(x_label_list)\n",
    "ax.set_yticklabels(y_label_list)\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_xlabel('Time (Hours)')\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "\n",
    "plt.imshow(a,extent = [0 , 168, 0 , 90], vmin=0, vmax=1, cmap=\"Blues\", interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e2314",
   "metadata": {},
   "source": [
    "## gradient_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "733d713f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 9)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e9e4970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b15d74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 168, 9)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6d2fbcfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "The Conv2D op currently does not support grouped convolutions on the CPU. A grouped convolution was attempted to be run because the input depth of 9 does not match the filter input depth of 1 [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13892/950125571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgrad_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivation_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mgrad_weight_abs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13892/3775030470.py\u001b[0m in \u001b[0;36mactivation_grad\u001b[1;34m(seq, model)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Obtain the predicted value and the intermediate filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mseq_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Extract filters and gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 386\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1016\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1018\u001b[1;33m       name=name)\n\u001b[0m\u001b[0;32m   1019\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1146\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m           name=name)\n\u001b[0m\u001b[0;32m   1149\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2590\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2591\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2592\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2593\u001b[0m   return squeeze_batch_dims(\n\u001b[0;32m   2594\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: The Conv2D op currently does not support grouped convolutions on the CPU. A grouped convolution was attempted to be run because the input depth of 9 does not match the filter input depth of 1 [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "id_=(24)*24+12\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_test = testX.copy()\n",
    "\n",
    "grad_weight = activation_grad(X_test, model)\n",
    "\n",
    "grad_weight_abs = abs(grad_weight)\n",
    "\n",
    "grad_weight_abs_z = (grad_weight_abs-(np.min(grad_weight_abs)))/(np.max(grad_weight_abs)-(np.min(grad_weight_abs)))\n",
    "#grad_weight=grad_weight.reshape(48,4)\n",
    "\n",
    "print(grad_weight_abs_z.shape)\n",
    "plt.figure(figsize=(6,20))\n",
    "\n",
    "#plt.plot(X_test[8], 'k')\n",
    "a=grad_weight_abs_z.numpy()\n",
    "a=a.reshape(168,9)\n",
    "a=a.transpose()\n",
    "\n",
    "#print(a)\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,5))\n",
    "\n",
    "extent = [0 , 168, 0 , 9]\n",
    "y_label_list = [1,3,5,7,9]\n",
    "x_label_list = [0,24,48,72,96,120,144,168]\n",
    "ax.set_xticks([0,24,48,72,96,120,144,168])\n",
    "\n",
    "ax.set_yticks([10,30,50,70,90])\n",
    "\n",
    "ax.set_xticklabels(x_label_list)\n",
    "ax.set_yticklabels(y_label_list)\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_xlabel('Time (Hours)')\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "\n",
    "plt.imshow(a,extent = [0 , 168, 0 , 90], vmin=0, vmax=1, cmap=\"Blues\", interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dbcc949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 30, 1)\n",
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "weights = tf.ones([3,3,1,1])\n",
    "X = tf.ones([1,32,32,1])\n",
    "Y = tf.nn.conv2d(X, weights, [1, 1, 1, 1], \"VALID\")\n",
    "print(Y.shape)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43906b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bike feature importance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
